{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_csv_filenames( path_to_dir, suffix=\".csv\" ):\n",
    "    filenames = listdir(path_to_dir)\n",
    "    return [ filename for filename in filenames if filename.endswith( suffix ) ]\n",
    "dfTuesday=pd.DataFrame()\n",
    "for idx,file in enumerate(find_csv_filenames('Netflow/CIC-IDS2017/pcaps/Benign')):\n",
    "    print(file,idx)\n",
    "    if dfTuesday.empty:\n",
    "        df=pd.read_csv('Netflow/CIC-IDS2017/pcaps/Benign/'+file)\n",
    "        df=pd.concat([df,pd.DataFrame({\"label\":[0 for i in range(len(df))]})],axis=1)\n",
    "        dfMonday=df\n",
    "    else:\n",
    "        df=pd.read_csv('Netflow/CIC-IDS2017/pcaps/Benign/'+file)\n",
    "        df=pd.concat([df,pd.DataFrame({\"label\":[0 for i in range(len(df))]})],axis=1)\n",
    "        dfMonday=pd.concat([dfMonday,df])\n",
    "dfMonday = dfMonday.sort_values(\"ts\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfMonday.dtos.value_counts())\n",
    "print(dfMonday.pr.value_counts())\n",
    "print(dfMonday.head())\n",
    "print(dfMonday.columns)\n",
    "print(len(dfMonday.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflow = pd.concat([dfMonday])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(netflow.label.unique())\n",
    "print(netflow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_order = [\"ts\", \"uid\", \"id.orig_h\", \"id.orig_p\", \"id.resp_h\", \"id.resp_p\", \"proto\", \"service\", \"duration\", \"orig_bytes\", \"resp_bytes\", \"conn_state\", \"local_orig\", \"local_resp\", \"missed_bytes\", \"history\", \"orig_pkts\", \"orig_ip_bytes\", \"resp_pkts\", \"resp_ip_bytes\",\t\"tunnel_parents\"]\n",
    "\n",
    "f=open(\"Netflow/CIC-IDS2017/pcaps/Tuesday/conn.log\",'r')\n",
    "lines = f.readlines()\n",
    "data = []\n",
    "for line in lines[8:-1]:\n",
    "    details = line.split('\t')\n",
    "    details = [x.strip() for x in details]\n",
    "    structure = {key: value for key, value in zip(conn_order, details)}\n",
    "    data.append(structure)\n",
    "\n",
    "df_temp = pd.DataFrame(data, columns=data[0].keys())\n",
    "anomaly = [1] * len(df_temp.index)\n",
    "df_temp['anomaly'] = anomaly\n",
    "#df_temp['ts_new'] = pd.to_datetime(df_temp['ts'], utc=True)\n",
    "df_temp=df_temp.sort_values('ts')\n",
    "df_temp['ts'] = df_temp['ts'].apply(lambda x: int(x.split('.')[0]))\n",
    "df_temp['ts'] = df_temp['ts'].apply(lambda x: str(datetime.fromtimestamp(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeek = pd.concat([df_temp])\n",
    "zeek.columns\n",
    "print(len(zeek.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zeek.columns)\n",
    "print(netflow.columns)\n",
    "#print(netflow.dir.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zeek.shape)\n",
    "print(netflow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeek.duration=pd.to_numeric(zeek.duration,errors='coerce')\n",
    "zeek=zeek.dropna()\n",
    "#zeek.ts=zeek.ts.astype(float)#+zeek.duration\n",
    "#zeek.ts=zeek.ts-zeek.ts.iloc[0]\n",
    "#zeek=zeek.sort_values('ts')\n",
    "#print(zeek.ts)\n",
    "\n",
    "netflow=netflow.dropna()\n",
    "netflow.dp=netflow.dp.astype(int)\n",
    "from datetime import datetime\n",
    "from time import mktime\n",
    "#netflow['ts'] =netflow['ts'].apply(lambda x: mktime(datetime.strptime(x,'%Y-%m-%d %H:%M:%S').timetuple()))\n",
    "#netflow.ts=netflow.ts#+netflow.td.astype(float)\n",
    "#netflow.ts=netflow.ts-netflow.ts.iloc[0]\n",
    "#netflow=netflow.sort_values('ts')\n",
    "#print(netflow.ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(netflow)\n",
    "print(zeek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflow.sa=netflow.sa.astype(str)\n",
    "netflow.da=netflow.da.astype(str)\n",
    "netflow.sp=netflow.sp.astype(int)\n",
    "netflow.dp=netflow.dp.astype(int)\n",
    "netflow.dp=netflow.dp.astype(int)\n",
    "netflow.ipkt=netflow.ipkt.astype(int)\n",
    "netflow.opkt=netflow.opkt.astype(int)\n",
    "\n",
    "zeek['id.orig_h']=zeek['id.orig_h'].astype(str)\n",
    "zeek['id.resp_h']=zeek['id.resp_h'].astype(str)\n",
    "zeek['id.orig_p']=zeek['id.orig_p'].astype(int)\n",
    "zeek['id.resp_p']=zeek['id.resp_p'].astype(int)\n",
    "zeek['orig_pkts']=zeek['orig_pkts'].astype(int)\n",
    "zeek['resp_pkts']=zeek['resp_pkts'].astype(int)\n",
    "netflow.sp=netflow.sp.astype(int)\n",
    "netflow.dp=netflow.dp.astype(int)\n",
    "netflow_to_zeek={\"sa\": \"id.orig_h\", \"da\": \"id.resp_h\",\"sp\":\"id.orig_p\",\"dp\":\"id.resp_p\"}\n",
    "netflow=netflow.rename(columns=netflow_to_zeek)\n",
    "common_cols = ['id.orig_h','id.resp_h','id.orig_p','id.resp_p']#,'orig_pkts','resp_pkts'] \n",
    "#netflow=netflow.drop_duplicates(subset=common_cols,keep='last')\n",
    "zeek=zeek.drop_duplicates(subset=common_cols,keep='last')\n",
    "df12 = pd.merge(netflow, zeek, on=common_cols, how='left')     #extract common rows with merge\n",
    "#df12=df12.dropna()\n",
    "df2 = zeek[~zeek['uid'].isin(df12['uid'])]\n",
    "#print(df12.columns)\n",
    "df3 = netflow[~netflow['ts'].isin(df12['ts_x'])]\n",
    "print(df12.shape)\n",
    "print(df2.shape)\n",
    "print(df3.shape)\n",
    "'''print(df2.iloc[0])\n",
    "#print(df3.iloc[0])\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df2[['ts']+common_cols])\n",
    "print(df3[['ts']+common_cols])'''\n",
    "zeek_to_netflow={v: k for k, v in netflow_to_zeek.items()}\n",
    "df12=df12.rename(columns=zeek_to_netflow)\n",
    "df12=df12.drop(['ts_y'],axis=1)\n",
    "df12=df12.rename(columns={'ts_x':'ts'})\n",
    "netflow=netflow.rename(columns=zeek_to_netflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12[netflow.columns.to_list()+['history']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df12.label.value_counts())\n",
    "print(df12.anomaly.value_counts())\n",
    "print(df12.history.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12.to_csv('Merged Zeek-Netflow/cic_monday.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df12))\n",
    "print(df12['history'].isna().sum())\n",
    "print(df12.isna())\n",
    "print(df12.label.unique())\n",
    "print(df12.sa.value_counts())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
