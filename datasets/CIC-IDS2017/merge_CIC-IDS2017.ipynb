{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from datetime import datetime\n",
    "from time import mktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_csv_filenames( path_to_dir, suffix=\".csv\" ):\n",
    "    filenames = listdir(path_to_dir)\n",
    "    return [ filename for filename in filenames if filename.endswith( suffix ) ]\n",
    "\n",
    "dfMalware=pd.DataFrame()\n",
    "for idx,file in enumerate(find_csv_filenames('./USTC-TFC2016/Malware')):\n",
    "    print(file,idx)\n",
    "    if dfMalware.empty:\n",
    "        df=pd.read_csv('./USTC-TFC2016/Malware/'+file)\n",
    "        df=pd.concat([df,pd.DataFrame({\"label\":[idx+1 for i in range(len(df))]})],axis=1)\n",
    "        dfMalware=df\n",
    "    else:\n",
    "        df=pd.read_csv('./USTC-TFC2016/Malware/'+file)\n",
    "        df=pd.concat([df,pd.DataFrame({\"label\":[idx+1 for i in range(len(df))]})],axis=1)\n",
    "        dfMalware=pd.concat([dfMalware,df])\n",
    "        \n",
    "dfBenign=pd.DataFrame()\n",
    "for file in find_csv_filenames('./USTC-TFC2016/Benign'):\n",
    "    print(file,idx)\n",
    "    if dfBenign.empty:\n",
    "        df=pd.read_csv('./USTC-TFC2016/Benign/'+file)\n",
    "        df=pd.concat([df,pd.DataFrame({\"label\":[0 for i in range(len(df))]})],axis=1)\n",
    "        dfBenign=df\n",
    "    else:\n",
    "        df=pd.read_csv('./USTC-TFC2016/Benign/'+file)\n",
    "        df=pd.concat([df,pd.DataFrame({\"label\":[0 for i in range(len(df))]})],axis=1)\n",
    "        dfBenign=pd.concat([dfBenign,df])\n",
    "netflow=pd.concat([dfBenign,dfMalware])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_order = [\"ts\", \"uid\", \"id.orig_h\", \"id.orig_p\", \"id.resp_h\", \"id.resp_p\", \"proto\", \"service\", \"duration\", \"orig_bytes\", \"resp_bytes\", \"conn_state\", \"local_orig\", \"local_resp\", \"missed_bytes\", \"history\", \"orig_pkts\", \"orig_ip_bytes\", \"resp_pkts\", \"resp_ip_bytes\",\t\"tunnel_parents\"]\n",
    "\n",
    "data={}\n",
    "data_mal={}\n",
    "for d in os.listdir(\"./zeek/Benign\"):\n",
    "    f=open(\"./zeek/Benign/\"+d+\"/conn.log\",'r')\n",
    "    lines = f.readlines()\n",
    "    data[d]=[]\n",
    "    for line in lines[8:-1]:\n",
    "        details = line.split('\t')\n",
    "        details = [x.strip() for x in details]\n",
    "        structure = {key: value for key, value in zip(conn_order, details)}\n",
    "        data[d].append(structure)\n",
    "        \n",
    "for d in os.listdir(\"./zeek/Malware\"):\n",
    "    f=open(\"./zeek/Malware/\"+d+\"/conn.log\",'r')\n",
    "    lines = f.readlines()\n",
    "    data_mal[d]=[]\n",
    "    for line in lines[8:-1]:\n",
    "        details = line.split('\t')\n",
    "        details = [x.strip() for x in details]\n",
    "        structure = {key: value for key, value in zip(conn_order, details)}\n",
    "        data_mal[d].append(structure)\n",
    "data_labeled=[]\n",
    "for d in data.keys():\n",
    "    df_temp = pd.DataFrame(data[d], columns=data[d][0].keys())\n",
    "    anomaly = [1] * len(df_temp.index)\n",
    "    df_temp['anomaly'] = anomaly \n",
    "    data_labeled.append(df_temp)\n",
    "\n",
    "df = pd.concat(data_labeled)\n",
    "\n",
    "data_mal_labeled=[]\n",
    "for d in data_mal.keys():\n",
    "    df_temp = pd.DataFrame(data_mal[d], columns=data_mal[d][0].keys())\n",
    "    anomaly = [-1] * len(df_temp.index)\n",
    "    df_temp['anomaly'] = anomaly \n",
    "    data_mal_labeled.append(df_temp)\n",
    "    \n",
    "df_anomaly = pd.concat(data_mal_labeled)\n",
    "zeek = pd.concat([df, df_anomaly])\n",
    "    \n",
    "#zeek = pd.DataFrame(zeek_data, columns=zeek_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zeek.columns)\n",
    "print(netflow.columns)\n",
    "#print(netflow.dir.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeek.duration=pd.to_numeric(zeek.duration,errors='coerce')\n",
    "zeek=zeek.dropna()\n",
    "#zeek.ts=zeek.ts.astype(float)#+zeek.duration\n",
    "#zeek.ts=zeek.ts-zeek.ts.iloc[0]\n",
    "#zeek=zeek.sort_values('ts')\n",
    "#print(zeek.ts)\n",
    "\n",
    "netflow=netflow.dropna()\n",
    "netflow.dp=netflow.dp.astype(int)\n",
    "#netflow['ts'] =netflow['ts'].apply(lambda x: mktime(datetime.strptime(x,'%Y-%m-%d %H:%M:%S').timetuple()))\n",
    "#netflow.ts=netflow.ts#+netflow.td.astype(float)\n",
    "#netflow.ts=netflow.ts-netflow.ts.iloc[0]\n",
    "#netflow=netflow.sort_values('ts')\n",
    "#print(netflow.ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(netflow)\n",
    "print(zeek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflow.sa=netflow.sa.astype(str)\n",
    "netflow.da=netflow.da.astype(str)\n",
    "netflow.sp=netflow.sp.astype(int)\n",
    "netflow.dp=netflow.dp.astype(int)\n",
    "netflow.dp=netflow.dp.astype(int)\n",
    "netflow.ipkt=netflow.ipkt.astype(int)\n",
    "netflow.opkt=netflow.opkt.astype(int)\n",
    "\n",
    "zeek['id.orig_h']=zeek['id.orig_h'].astype(str)\n",
    "zeek['id.resp_h']=zeek['id.resp_h'].astype(str)\n",
    "zeek['id.orig_p']=zeek['id.orig_p'].astype(int)\n",
    "zeek['id.resp_p']=zeek['id.resp_p'].astype(int)\n",
    "zeek['orig_pkts']=zeek['orig_pkts'].astype(int)\n",
    "zeek['resp_pkts']=zeek['resp_pkts'].astype(int)\n",
    "netflow.sp=netflow.sp.astype(int)\n",
    "netflow.dp=netflow.dp.astype(int)\n",
    "netflow_to_zeek={\"sa\": \"id.orig_h\", \"da\": \"id.resp_h\",\"sp\":\"id.orig_p\",\"dp\":\"id.resp_p\"}\n",
    "netflow=netflow.rename(columns=netflow_to_zeek)\n",
    "common_cols = ['id.orig_h','id.resp_h','id.orig_p','id.resp_p']#,'orig_pkts','resp_pkts'] \n",
    "#netflow=netflow.drop_duplicates(subset=common_cols,keep='last')\n",
    "zeek=zeek.drop_duplicates(subset=common_cols,keep='last')\n",
    "df12 = pd.merge(netflow, zeek, on=common_cols, how='left')     #extract common rows with merge\n",
    "#df12=df12.dropna()\n",
    "df2 = zeek[~zeek['uid'].isin(df12['uid'])]\n",
    "#print(df12.columns)\n",
    "df3 = netflow[~netflow['ts'].isin(df12['ts_x'])]\n",
    "print(df12.shape)\n",
    "print(df2.shape)\n",
    "print(df3.shape)\n",
    "'''print(df2.iloc[0])\n",
    "#print(df3.iloc[0])\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df2[['ts']+common_cols])\n",
    "print(df3[['ts']+common_cols])'''\n",
    "zeek_to_netflow={v: k for k, v in netflow_to_zeek.items()}\n",
    "df12=df12.rename(columns=zeek_to_netflow)\n",
    "df12=df12.drop(['ts_y'],axis=1)\n",
    "df12=df12.rename(columns={'ts_x':'ts'})\n",
    "netflow=netflow.rename(columns=zeek_to_netflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df12[netflow.columns.to_list()+['history']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12.to_csv('./merged_ustc.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df12))\n",
    "print(df12['history'].isna().sum())\n",
    "print(df12.isna())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
